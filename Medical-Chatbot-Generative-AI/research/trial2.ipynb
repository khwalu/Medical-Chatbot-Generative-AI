{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc47d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7298fbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\TOBBY\\\\Documents\\\\thanzilanga\\\\Research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8f7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47329da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\TOBBY\\\\Documents\\\\thanzilanga'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f54d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOBBY\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\TOBBY\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at db_data_2025-04.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e792c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cad363f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables validated\n"
     ]
    }
   ],
   "source": [
    "def validate_environment():\n",
    "    \"\"\"Validate required environment variables\"\"\"\n",
    "    required_vars = ['PINECONE_API_KEY', 'GEMINI_API_KEY']\n",
    "    missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "    \n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    \n",
    "    print(\"✓ Environment variables validated\")\n",
    "\n",
    "# Validate environment before proceeding\n",
    "validate_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24644963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully loaded 759 PDF documents\n",
      "Total documents: 759\n"
     ]
    }
   ],
   "source": [
    "# Enhanced PDF Loading with Error Handling\n",
    "def load_pdf_file(data):\n",
    "    \"\"\"Extract Data From the PDF File - Enhanced with error handling\"\"\"\n",
    "    try:\n",
    "        loader = DirectoryLoader(data,\n",
    "                               glob=\"*.pdf\",\n",
    "                               loader_cls=PyPDFLoader)\n",
    "        documents = loader.load()\n",
    "        print(f\"✓ Successfully loaded {len(documents)} PDF documents\")\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading PDF files: {e}\")\n",
    "        return []\n",
    "try:\n",
    "    extracted_data = load_pdf_file(data='data/')\n",
    "    print(f\"Total documents: {len(extracted_data)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load documents: {e}\")\n",
    "    extracted_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de91c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Filtered to 759 minimal documents\n"
     ]
    }
   ],
   "source": [
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs\n",
    "\n",
    "# Apply filtering with error handling - keeping your variable name\n",
    "try:\n",
    "    minimal_docs = filter_to_minimal_docs(extracted_data)\n",
    "    print(f\"✓ Filtered to {len(minimal_docs)} minimal documents\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error filtering documents: {e}\")\n",
    "    minimal_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb5fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 6973 text chunks\n",
      "Length of Text Chunks 6973\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Text Splitting - keeping your exact function name\n",
    "def text_split(minimal_docs):\n",
    "    \"\"\"Split the Data into Text Chunks - Enhanced with error handling\"\"\"\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500, \n",
    "            chunk_overlap=20,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Better separators\n",
    "        )\n",
    "        text_chunks = text_splitter.split_documents(minimal_docs)\n",
    "        print(f\"✓ Created {len(text_chunks)} text chunks\")\n",
    "        return text_chunks\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error splitting text: {e}\")\n",
    "        return []\n",
    "\n",
    "# Your original variable names preserved\n",
    "text_chunks = text_split(minimal_docs)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7c6aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Error initializing embeddings: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:19\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     AutoConfig,\n\u001b[32m     21\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     22\u001b[39m     AutoTokenizer,\n\u001b[32m     23\u001b[39m     PretrainedConfig,\n\u001b[32m     24\u001b[39m     PreTrainedModel,\n\u001b[32m     25\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2154\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2154\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2155\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2184\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2182\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:21\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     _BaseAutoBackboneClass,\n\u001b[32m     23\u001b[39m     _BaseAutoModelClass,\n\u001b[32m     24\u001b[39m     _LazyAutoMapping,\n\u001b[32m     25\u001b[39m     auto_class_update,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_MAPPING_NAMES\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:43\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[32m     46\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'GenerationMixin' from 'transformers.generation' (c:\\Users\\TOBBY\\Documents\\conda\\envs\\medibot\\Lib\\site-packages\\transformers\\generation\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✗ Error initializing embeddings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m embeddings = \u001b[43mdownload_hugging_face_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     15\u001b[39m     query_result = embeddings.embed_query(\u001b[33m\"\u001b[39m\u001b[33mHello world\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mdownload_hugging_face_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Download the Embeddings from Hugging Face - Enhanced with error handling\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     embeddings = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ HuggingFace embeddings initialized successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\embeddings\\huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "#Enhanced Embeddings \n",
    "def download_hugging_face_embeddings():\n",
    "    \"\"\"Download the Embeddings from Hugging Face - Enhanced with error handling\"\"\"\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "        print(\"✓ HuggingFace embeddings initialized successfully\")\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error initializing embeddings: {e}\")\n",
    "        raise\n",
    "    \n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "try:\n",
    "    query_result = embeddings.embed_query(\"Hello world\")\n",
    "    print(\"Length\", len(query_result))\n",
    "    print(\"✓ Embeddings test successful\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Embeddings test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b52fd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API keys retrieved from environment\n"
     ]
    }
   ],
   "source": [
    "#Enhanced API Key Management\n",
    "try:\n",
    "    PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "    GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
    "    \n",
    "    if not PINECONE_API_KEY:\n",
    "        raise ValueError(\"PINECONE_API_KEY environment variable not set\")\n",
    "    if not GEMINI_API_KEY:\n",
    "        raise ValueError(\"GEMINI_API_KEY environment variable not set\")\n",
    "        \n",
    "    print(\"✓ API keys retrieved from environment\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error getting API keys: {e}\")\n",
    "    raise\n",
    "pinecone_api_key = PINECONE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ed14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pinecone client initialized\n",
      "✓ Using existing index: medicalbot\n",
      "✓ Index ready\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Pinecone Setup\n",
    "try:\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "    print(\"✓ Pinecone client initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error initializing Pinecone: {e}\")\n",
    "    raise\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "# Enhanced Index Management\n",
    "try:\n",
    "    if not pc.has_index(index_name):        \n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\", \n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "        print(f\"✓ Created new index: {index_name}\")\n",
    "    else:\n",
    "        print(f\"✓ Using existing index: {index_name}\")\n",
    "        \n",
    "    index = pc.Index(index_name)\n",
    "    print(\"✓ Index ready\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error with index: {e}\")\n",
    "    raise\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cffbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vector store created with 12832 documents\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Vector Store Creation \n",
    "def create_or_load_docsearch(text_chunks, index_name, embeddings):\n",
    "    \"\"\"Create or load vector store with fallback\"\"\"\n",
    "    if not text_chunks:\n",
    "        print(\"⚠ No text chunks available, loading existing vector store\")\n",
    "        return PineconeVectorStore.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        docsearch = PineconeVectorStore.from_documents(\n",
    "            documents=text_chunks,\n",
    "            index_name=index_name,\n",
    "            embedding=embeddings, \n",
    "        )\n",
    "        print(f\"✓ Vector store created with {len(text_chunks)} documents\")\n",
    "        return docsearch\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error creating vector store: {e}\")\n",
    "        print(\"⚠ Attempting to load existing vector store...\")\n",
    "        return PineconeVectorStore.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "\n",
    "# Your original variable name preserved\n",
    "docsearch = create_or_load_docsearch(text_chunks, index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5eac2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Existing vector store loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Enhanced existing vector store loading\n",
    "try:\n",
    "    # Load Existing index \n",
    "    docsearch_existing = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    print(\"✓ Existing vector store loaded successfully\")\n",
    "    # Use the existing one to ensure we have data\n",
    "    docsearch = docsearch_existing\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not load existing vector store: {e}\")\n",
    "    # Keep the newly created one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd6fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added custom document successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dswith = Document(\n",
    "        page_content=\"dswithbappy is a youtube channel that provides tutorials on various topics.\",\n",
    "        metadata={\"source\": \"Youtube\"}\n",
    "    )\n",
    "    docsearch.add_documents(documents=[dswith])\n",
    "    print(\"✓ Added custom document successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error adding custom document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd58ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retriever configured successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "    print(\"✓ Retriever configured successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error setting up retriever: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2085a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retrieved 3 documents for test query\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    retrieved_docs = retriever.invoke(\"What is Cardiac shunt?\")\n",
    "    print(f\"✓ Retrieved {len(retrieved_docs)} documents for test query\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error testing retrieval: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b662370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='eb0b9689-66c0-466d-a6da-7f8d108527cc', metadata={'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf'}, page_content='weak spot in the wall of an artery or heart chamber.\\nCardiac shunt —A defect in the wall of the heart\\nthat allows blood from different chambers to mix.\\nCoronary occlusive artery disease —Blockage of\\nthe arteries that supply blood to the heart; fre-\\nquently a precursor to a heart attack.\\nElectrocardiogram (ECG)—A graph that shows the\\nelectrical charges that trigger the heart to contract.\\nHeart abnormalities alter the graph, giving clues to\\nthe source of the abnormality.'),\n",
       " Document(id='1f8bb4cb-79cb-418b-aea3-ef0b51957ec1', metadata={'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf'}, page_content='weak spot in the wall of an artery or heart chamber.\\nCardiac shunt —A defect in the wall of the heart\\nthat allows blood from different chambers to mix.\\nCoronary occlusive artery disease —Blockage of\\nthe arteries that supply blood to the heart; fre-\\nquently a precursor to a heart attack.\\nElectrocardiogram (ECG)—A graph that shows the\\nelectrical charges that trigger the heart to contract.\\nHeart abnormalities alter the graph, giving clues to\\nthe source of the abnormality.'),\n",
       " Document(id='d7fd9c99-db45-4844-b12e-eb693f348c9f', metadata={'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf'}, page_content='weak spot in the wall of an artery or heart chamber.\\nCardiac shunt —A defect in the wall of the heart\\nthat allows blood from different chambers to mix.\\nCoronary occlusive artery disease —Blockage of\\nthe arteries that supply blood to the heart; fre-\\nquently a precursor to a heart attack.\\nElectrocardiogram (ECG)—A graph that shows the\\nelectrical charges that trigger the heart to contract.\\nHeart abnormalities alter the graph, giving clues to\\nthe source of the abnormality.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa483911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Chat model initialized successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Enhanced Chat Model Setup\n",
    "try:\n",
    "    chatModel = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        google_api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "        temperature=0.1,  \n",
    "        max_output_tokens=1000 \n",
    "    )\n",
    "    print(\"✓ Chat model initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error initializing chat model: {e}\")\n",
    "    raise\n",
    "system_prompt = (\n",
    "    \"You are NthanziLanga+ AI assistant, created by TecNix to help with health-related questions and information. \"\n",
    "    \"You are designed to provide helpful, accurate health guidance while encouraging users to consult healthcare professionals for medical advice. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c023da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prompt template created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    print(\"✓ Prompt template created\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating prompt: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bff2a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG chain created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    print(\"✓ RAG chain created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating RAG chain: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b56885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enhanced query execution - keeping your exact structure\n",
    "def execute_query(rag_chain, query):\n",
    "    \"\"\"Execute query with error handling\"\"\"\n",
    "    try:\n",
    "        response = rag_chain.invoke({\"input\": query})\n",
    "        print(f\"✓ Query processed successfully: {query}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing query '{query}': {e}\")\n",
    "        return {\"answer\": \"Sorry, I encountered an error processing your question.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe529b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"what is malaria?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was created by Google.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"who created you?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2000ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have information on the signs and symptoms of malaria.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"what are signs and symptoms of malaria?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am not able to provide medical advice.  The provided text gives general advice for acne care (shampooing frequently, a balanced diet, limited sun exposure, not picking blemishes, and stress reduction), but does not offer specific prescription recommendations.  You should consult a dermatologist or other qualified healthcare professional for diagnosis and treatment of acne.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"if a person has alot of pimples on her or his face what should we prescribe them?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have enough information to answer your question.  The provided text only shows metadata indicating that the information about acne is located in the Gale Encyclopedia of Medicine, but it doesn't provide the actual definition of acne.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"what is acne?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc313a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact cause of acne is unknown.  Several risk factors include age (teenagers are more prone due to hormonal changes), gender (boys tend to have more severe acne), hormonal disorders, and heredity.  Consult a healthcare professional for diagnosis and treatment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"what causes acne?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f33c734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This information comes from the contents page of the Gale Encyclopedia of Medicine, Volume 5 (T-Z).  The provided text shows the page numbers for the main content, organizations listed, and the general index.  It appears to be a table of contents.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"where did you these information from?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f5bb2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text mentions page numbers 525 and 521.  More context is needed to determine which page is relevant to your specific question.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"can you give the page number?\"})\n",
    "    print(response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in original query: {e}\")\n",
    "    response = {\"answer\": \"Error occurred during query processing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812bead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
